{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statements\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "SPY_daily = yf.download('SPY')\n",
    "energy_daily = yf.download('XLE')\n",
    "materials_daily = yf.download('XLB')\n",
    "industrial_daily = yf.download('XLI')\n",
    "utilities_daily = yf.download('XLU')\n",
    "health_daily = yf.download('XLV')\n",
    "financial_daily = yf.download('XLF')\n",
    "consumer_discretionary_daily = yf.download('XLY')\n",
    "consumer_staples_daily = yf.download('XLP')\n",
    "technology_daily = yf.download('XLK')\n",
    "real_estate_daily = yf.download('VGSIX')\n",
    "TYBonds_daily = yf.download('^TNX')\n",
    "VIX_daily = yf.download('^VIX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SMA(df, feature, window_size):\n",
    "    new_col = 'MA' + feature + str(window_size)\n",
    "    df[new_col] = df[feature].rolling(window=window_size).mean()\n",
    "    return df\n",
    "\n",
    "def Volitility(df, feature, window_size):\n",
    "    new_col = 'VOLITILITY' + feature + str(window_size)\n",
    "    returns = np.log(df[feature]/df[feature].shift())\n",
    "    returns.fillna(0, inplace=True)\n",
    "    df[new_col] = returns.rolling(window=window_size).std()*np.sqrt(window_size)\n",
    "    return df\n",
    "\n",
    "def RSI(df, feature, window_size):\n",
    "    new_col = 'RSI' + feature + str(window_size)\n",
    "    delta = df[feature].diff()\n",
    "    delta = delta[1:]\n",
    "    up, down = delta.clip(lower=0), delta.clip(upper=0)\n",
    "    roll_up = up.rolling(window_size).mean()\n",
    "    roll_down = down.abs().rolling(window_size).mean()\n",
    "    RS = roll_up / roll_down\n",
    "    RSI = 100.0 - (100.0 / (1.0 + RS))\n",
    "    df[new_col] = RSI\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6205, 26)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get only close and volume from each DF\n",
    "\n",
    "\n",
    "input_params = pd.DataFrame()\n",
    "\n",
    "ticker_columns = [\n",
    "    SPY_daily.Close, SPY_daily.Volume, \n",
    "    energy_daily.Close, energy_daily.Volume,\n",
    "    materials_daily.Close, materials_daily.Volume,\n",
    "    industrial_daily.Close, industrial_daily.Volume,\n",
    "    utilities_daily.Close, utilities_daily.Volume, \n",
    "    health_daily.Close, health_daily.Volume,\n",
    "    financial_daily.Close, financial_daily.Volume,\n",
    "    consumer_discretionary_daily.Close, consumer_discretionary_daily.Volume,\n",
    "    consumer_staples_daily.Close, consumer_staples_daily.Volume,\n",
    "    technology_daily.Close, technology_daily.Volume,\n",
    "    real_estate_daily.Close, real_estate_daily.Volume,\n",
    "    TYBonds_daily.Close, TYBonds_daily.Volume,\n",
    "    VIX_daily.Close, VIX_daily.Volume,\n",
    "    ]\n",
    "\n",
    "ticker_column_names = [\n",
    "    \"close_SPY\"                        , \"volume_SPY\"                    ,\n",
    "    \"close_energy\"                     , \"volume_energy\"                 ,\n",
    "    \"close_materials\"                  , \"volume_materials\"              ,\n",
    "    \"close_industrial\"                 , \"volume_industrial\"             ,\n",
    "    \"close_utilities\"                  , \"volume_utilities\"              ,\n",
    "    \"close_health\"                     , \"volume_health\"                 ,\n",
    "    \"close_financial\"                  , \"volume_financial\"              ,\n",
    "    \"close_consumer_discretionary\"     , \"volume_consumer_discretionary\" ,\n",
    "    \"close_consumer_staples\"           , \"volume_consumer_staples\"       ,\n",
    "    \"close_technology\"                 , \"volume_technology\"             ,\n",
    "    \"close_real_estate\"                , \"volume_real_estate\"            ,\n",
    "    \"close_TYBonds\"                    , \"volume_TYBonds\"                ,\n",
    "    \"close_VIX\"                        , \"volume_VIX\"                    ,\n",
    "]\n",
    "\n",
    "# combine into one mega frame\n",
    "\n",
    "input_params = pd.concat(ticker_columns, axis='columns')\n",
    "\n",
    "input_params.columns = ticker_column_names\n",
    "\n",
    "input_params = input_params.dropna()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wujor\\AppData\\Local\\Temp\\ipykernel_30032\\90966104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col] = df[feature].rolling(window=window_size).mean()\n",
      "C:\\Users\\wujor\\AppData\\Local\\Temp\\ipykernel_30032\\90966104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col] = df[feature].rolling(window=window_size).mean()\n",
      "C:\\Users\\wujor\\AppData\\Local\\Temp\\ipykernel_30032\\90966104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col] = df[feature].rolling(window=window_size).mean()\n",
      "C:\\Users\\wujor\\AppData\\Local\\Temp\\ipykernel_30032\\90966104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col] = df[feature].rolling(window=window_size).mean()\n",
      "C:\\Users\\wujor\\AppData\\Local\\Temp\\ipykernel_30032\\90966104.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col] = df[feature].rolling(window=window_size).mean()\n"
     ]
    }
   ],
   "source": [
    "# calculate technical indicators for 7, 20,50, and 200 day windows\n",
    "for window_size in [7, 20, 50, 200]:\n",
    "    for feature in ticker_column_names:\n",
    "        input_params = SMA(input_params, feature, window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Daily_Volatility(close,span0=20):\n",
    "    # simple percentage returns\n",
    "    df0=close.pct_change()\n",
    "    # 20 days, a month EWM's std as boundary\n",
    "    df0=df0.ewm(span=span0).std()\n",
    "    df0.dropna(inplace=True)\n",
    "    return df0\n",
    "\n",
    "def get_3_barriers(daily_volatility, prices):\n",
    "    #create a container\n",
    "    barriers = pd.DataFrame(columns=['days_passed', \n",
    "              'price', 'vert_barrier', \\\n",
    "              'top_barrier', 'bottom_barrier'], \\\n",
    "               index = daily_volatility.index)\n",
    "\n",
    "    for day, vol in daily_volatility.iteritems():\n",
    "        days_passed = len(daily_volatility.loc[daily_volatility.index[0] : day])\n",
    "        #set the vertical barrier \n",
    "        if (days_passed + t_final < len(daily_volatility.index) and t_final != 0):\n",
    "            vert_barrier = daily_volatility.index[days_passed + t_final]\n",
    "        else:\n",
    "            vert_barrier = np.nan\n",
    "        #set the top barrier\n",
    "        if upper_lower_multipliers[0] > 0:\n",
    "            top_barrier = prices.loc[day] + prices.loc[day] * upper_lower_multipliers[0] * vol\n",
    "        else:\n",
    "            #set it to NaNs\n",
    "            top_barrier = pd.Series(index=prices.index)\n",
    "        #set the bottom barrier\n",
    "        if upper_lower_multipliers[1] > 0:\n",
    "            bottom_barrier = prices.loc[day] - prices.loc[day] * upper_lower_multipliers[1] * vol\n",
    "        else: \n",
    "            #set it to NaNs\n",
    "            bottom_barrier = pd.Series(index=prices.index)\n",
    "        barriers.loc[day, ['days_passed', 'price', 'vert_barrier','top_barrier', 'bottom_barrier']] = \\\n",
    "            days_passed, prices.loc[day], vert_barrier, \\\n",
    "            top_barrier, bottom_barrier\n",
    "\n",
    "    return barriers\n",
    "\n",
    "def get_labels(barriers):\n",
    "\n",
    "    labels = []\n",
    "    size = [] # percent gained or lossed \n",
    "\n",
    "    for i in range(len(barriers.index)):\n",
    "        start = barriers.index[i]\n",
    "        end = barriers.vert_barrier[i]\n",
    "        if pd.notna(end):\n",
    "            # assign the initial and final price\n",
    "            price_initial = barriers.price[start]\n",
    "            price_final = barriers.price[end]\n",
    "            # assign the top and bottom barriers\n",
    "            top_barrier = barriers.top_barrier[i]\n",
    "            bottom_barrier = barriers.bottom_barrier[i]\n",
    "            #set the profit taking and stop loss conditons\n",
    "            condition_pt = (barriers.price[start: end] >= top_barrier).any()\n",
    "            condition_sl = (barriers.price[start: end] <= bottom_barrier).any()\n",
    "            #assign the labels\n",
    "            if condition_pt: \n",
    "                labels.append(1)\n",
    "            else: \n",
    "                labels.append(0)\n",
    "            size.append((price_final - price_initial) / price_initial)\n",
    "        else:\n",
    "            labels.append(np.nan)\n",
    "            size.append(np.nan)\n",
    "\n",
    "    return labels, size\n",
    "\n",
    "# how many days we hold the stock which set the vertical barrier\n",
    "t_final = 10\n",
    "#the up and low boundary multipliers\n",
    "upper_lower_multipliers = [2, 2]\n",
    "#allign the index\n",
    "\n",
    "#vol_df = get_Daily_Volatility(full_df.SPY_Close)\n",
    "#prices = full_df.SPY_Close[vol_df.index]\n",
    "#barriers = get_3_barriers(vol_df, prices)\n",
    "#barriers.index = pd.to_datetime(barriers.index)\n",
    "#labs, size = get_labels(barriers)\n",
    "#full_df = full_df[full_df.index.isin(barriers.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "supreme-robot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
